package model;

import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import classification.BayesMethod;
import classification.KnnMethod;
import classification.KeywordMethod;
import model.TweetAction.Rate;
import view.BarChart;
import view.PieChart;

public class AnalizeStats {
	List<List<Tweet>> set;
	Map<Tweet, Integer> ref;
	Map<String, Float> dataBase;
	Map<String, Integer> dataBayes;
	Map<String, Integer> dataKnnKeyword;
	private static int nbSubset = 10;


	public AnalizeStats() {
		dataBase = new HashMap<String, Float>();
		dataKnnKeyword = new HashMap<String, Integer>();
		dataBayes = new HashMap<String, Integer>();
		TweetAction.loadBaseTweet();

		try {
			calcErrorRate();
		} catch (IOException e) {
			System.out.println(e.getMessage());
			System.out.println("AnalizeStats:construc");
		}
		createRatioBase();

		new PieChart("Ratio Tweets Base", dataBase);
		new BarChart("Statistiques Knn & KeyWord", dataKnnKeyword);
		new BarChart("Statistiques Bayes", dataBayes);
	}


	public void initSets() {
		set = new ArrayList<List<Tweet>>(nbSubset);
		ref = new HashMap<Tweet, Integer>();
		for (int i = 0; i < nbSubset; i++) {
			set.add(new ArrayList<Tweet>());
		}
	}


	public void createSubsets() throws IOException {
		List<Tweet> base = TweetAction.getBase();
		int neg, pos, neutre;
		neg = neutre = pos = 0;
		initSets();

		for (Tweet tweetInfos : base) {

			switch (tweetInfos.getNote()) {
			case 0:
				if (neg >= nbSubset)
					neg = 0;
				ref.put(tweetInfos, tweetInfos.getNote());
				set.get(neg).add(tweetInfos);
				neg++;
				break;
			case 2:
				if (neutre >= nbSubset)
					neutre = 0;
				ref.put(tweetInfos, tweetInfos.getNote());
				set.get(neutre).add(tweetInfos);
				neutre++;
				break;
			case 4:
				if (pos >= nbSubset)
					pos = 0;
				ref.put(tweetInfos, tweetInfos.getNote());
				set.get(pos).add(tweetInfos);
				pos++;
				break;
			}

		}
		for (List<Tweet> sous : set) {
			System.out.println("Taille " + sous.size());
		}

	}

	/**
	 * Calculate the % error rate of each algo 
	 * @throws IOException
	 */
	void calcErrorRate() throws IOException{
		int classeKnn, classeBayesUniFreq, classeBayesUniPres, classeBayesBiGFreq, classeBayesBiGPres, classePosNeg;
		int errKnn, errBayesUniFreq, errBayesUniPres, errBayesBigFreq, errBayesBigPres, errPosNeg;
		errBayesUniFreq = errBayesBigFreq = errBayesBigPres = errBayesUniPres = errKnn = errPosNeg = 0;

		try {
			createSubsets();
		} catch (IOException e) {
			System.out.println("Erreur lors de la creation des sous ensembles");
		}

		for (int i = 0; i < nbSubset; i++) {
			List<Tweet> baseCalcul = concatEnsemble(i);

			for (Tweet tweetcourrant : set.get(i)) {
				classeKnn = KnnMethod.knn(tweetcourrant.getTweet(), 30,
						baseCalcul);


				classePosNeg = KeywordMethod.getClassePosNeg(tweetcourrant
						.getTweet());

				classeBayesUniPres = BayesMethod.classifierBayes(baseCalcul,
						tweetcourrant.getTweet(), 0);
				/*
				 * classeBayesUniFreq = ClassifBayes.classifierBayes(baseCalcul,
				 * tweetcourrant.getTweet(), 1); classeBayesBiGPres =
				 * ClassifBayesBiGramme .classifierBayesBiGramme(baseCalcul,
				 * tweetcourrant.getTweet(), 0); classeBayesBiGFreq =
				 * ClassifBayesBiGramme .classifierBayesBiGramme(baseCalcul,
				 * tweetcourrant.getTweet(), 1);
				 */

				// Verification de la notation de chaque classifieur
				if (classeKnn != ref.get(tweetcourrant)) {
					errKnn++;
				}

				if (classePosNeg != ref.get(tweetcourrant)) {
					errPosNeg++;
				}
				if (classeBayesUniPres != ref.get(tweetcourrant)) {
					errBayesUniPres++;

				}
				/*
				 * if (classeBayesUniFreq != reference.get(tweetcourrant)) {
				 * errBayesUniFreq++;
				 * 
				 * } if (classeBayesBiGFreq != reference.get(tweetcourrant)) {
				 * errBayesBigFreq++; } if (classeBayesBiGPres !=
				 * reference.get(tweetcourrant)) { errBayesBigPres++; }
				 */

			}
		}

		// Enregistrement des données
		dataBayes.put("UnigrammeFreq",
				(int) (((float) errBayesUniFreq / ref.size()) * 100));
		dataBayes.put("UnigrammePres",
				(int) (((float) errBayesUniPres / ref.size()) * 100));
		dataBayes.put("BigrammeFreq",
				(int) (((float) errBayesBigFreq / ref.size()) * 100));
		dataBayes.put("BigrammePres",
				(int) (((float) errBayesBigPres / ref.size()) * 100));

		dataKnnKeyword.put("Knn",
				(int) (((float) errKnn / ref.size()) * 100));
		dataKnnKeyword.put("Pos/Neg",
				(int) (((float) errPosNeg / ref.size()) * 100));

	}

	/**
	 * Fait l'union de tout les sous-ensembles sauf celui qui doit être noté
	 * 
	 * @param exception
	 *            indice du sous-ensemble à ne pas prendre en compte
	 * @return la liste de tweet des sous-ensembles concaténés
	 */
	public List<Tweet> concatEnsemble(int exception) {
		List<Tweet> concat = new ArrayList<Tweet>();
		for (int i = 0; i < set.size(); i++) {
			if (i != exception) {
				concat.addAll(set.get(i));
			}
		}

		System.out.println("Taille BaseUnion : " + concat.size());
		return concat;
	}

	/**
	 * Calcule le ratio des tweets positifs, negatifs et neutres de la base
	 * d'apprentissage
	 */
	public void createRatioBase() {
		float pos, neg, neutre;
		int total = TweetAction.getBase().size();

		pos = ((float) TweetAction.getTweetByClasse(Rate.POSITIVE).size() / total) * 100;
		neg = ((float) TweetAction.getTweetByClasse(Rate.NEGATIVE).size() / total) * 100;
		neutre = ((float) TweetAction.getTweetByClasse(Rate.NEUTRAL).size() / total) * 100;
		dataBase.put("Positif", pos);
		dataBase.put("Negatif", neg);
		dataBase.put("Neutre", neutre);

	}

}
